# tests/verifications/config.yaml
providers:
  openai:
    models:
      - gpt-4o
      - gpt-4o-mini
    model_display_names:
        "gpt-4o": "gpt-4o"
        "gpt-4o-mini": "gpt-4o-mini"
    test_exclusions: {} # No exclusions currently for openai models

  fireworks:
    models:
      - accounts/fireworks/models/llama-v3p3-70b-instruct
      - accounts/fireworks/models/llama4-scout-instruct-basic
      - accounts/fireworks/models/llama4-maverick-instruct-basic
    model_display_names:
        "accounts/fireworks/models/llama-v3p3-70b-instruct": "Llama-3.3-70B-Instruct"
        "accounts/fireworks/models/llama4-scout-instruct-basic": "Llama-4-Scout-Instruct"
        "accounts/fireworks/models/llama4-maverick-instruct-basic": "Llama-4-Maverick-Instruct"
    test_exclusions:
      accounts/fireworks/models/llama-v3p3-70b-instruct:
        - test_chat_non_streaming_image
        - test_chat_streaming_image

  together:
    models:
      - meta-llama/Llama-3.3-70B-Instruct-Turbo
      - meta-llama/Llama-4-Scout-17B-16E-Instruct
      - meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
    model_display_names:
        "meta-llama/Llama-3.3-70B-Instruct-Turbo": "Llama-3.3-70B-Instruct"
        "meta-llama/Llama-4-Scout-17B-16E-Instruct": "Llama-4-Scout-Instruct"
        "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": "Llama-4-Maverick-Instruct"
    test_exclusions:
      meta-llama/Llama-3.3-70B-Instruct-Turbo:
        - test_chat_non_streaming_image
        - test_chat_streaming_image

  groq:
    models:
      - llama-3.3-70b-versatile
      - llama-4-scout-17b-16e-instruct
      - llama-4-maverick-17b-128e-instruct
    model_display_names:
        "llama-3.3-70b-versatile": "Llama-3.3-70B-Instruct"
        "llama-4-scout-17b-16e-instruct": "Llama-4-Scout-Instruct"
        "llama-4-maverick-17b-128e-instruct": "Llama-4-Maverick-Instruct"
    test_exclusions:
      llama-3.3-70b-versatile:
        - test_chat_non_streaming_image
        - test_chat_streaming_image

  cerebras:
    models:
      - llama-3.3-70b
    model_display_names:
        "llama-3.3-70b": "Llama-3.3-70B-Instruct"
    test_exclusions:
      llama-3.3-70b:
        - test_chat_non_streaming_image
        - test_chat_streaming_image