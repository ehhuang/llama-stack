{
  "created": 1744915514.208135,
  "duration": 202.18266344070435,
  "exitcode": 0,
  "root": "/home/erichuang/llama-stack",
  "environment": {},
  "summary": {
    "passed": 28,
    "total": 28,
    "collected": 28
  },
  "collectors": [
    {
      "nodeid": "",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py",
          "type": "Module"
        }
      ]
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]",
          "type": "Function",
          "lineno": 95
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]",
          "type": "Function",
          "lineno": 95
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]",
          "type": "Function",
          "lineno": 114
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]",
          "type": "Function",
          "lineno": 114
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
          "type": "Function",
          "lineno": 138
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
          "type": "Function",
          "lineno": 157
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]",
          "type": "Function",
          "lineno": 181
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[meta-llama/Llama-4-Scout-17B-16E-Instruct-math]",
          "type": "Function",
          "lineno": 181
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]",
          "type": "Function",
          "lineno": 204
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[meta-llama/Llama-4-Scout-17B-16E-Instruct-math]",
          "type": "Function",
          "lineno": 204
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
          "type": "Function",
          "lineno": 226
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
          "type": "Function",
          "lineno": 250
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
          "type": "Function",
          "lineno": 278
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
          "type": "Function",
          "lineno": 302
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
          "type": "Function",
          "lineno": 329
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
          "type": "Function",
          "lineno": 352
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]",
          "type": "Function",
          "lineno": 380
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]",
          "type": "Function",
          "lineno": 380
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]",
          "type": "Function",
          "lineno": 380
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]",
          "type": "Function",
          "lineno": 380
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]",
          "type": "Function",
          "lineno": 380
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]",
          "type": "Function",
          "lineno": 471
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]",
          "type": "Function",
          "lineno": 471
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]",
          "type": "Function",
          "lineno": 471
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]",
          "type": "Function",
          "lineno": 471
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]",
          "type": "Function",
          "lineno": 471
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=False]",
          "type": "Function",
          "lineno": 554
        },
        {
          "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=True]",
          "type": "Function",
          "lineno": 554
        }
      ]
    }
  ],
  "tests": [
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]",
      "lineno": 95,
      "outcome": "passed",
      "keywords": [
        "test_chat_non_streaming_basic[meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-earth",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "earth"
      },
      "setup": {
        "duration": 0.09510238654911518,
        "outcome": "passed"
      },
      "call": {
        "duration": 2.7976166242733598,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0002804817631840706,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]",
      "lineno": 95,
      "outcome": "passed",
      "keywords": [
        "test_chat_non_streaming_basic[meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "saturn"
      },
      "setup": {
        "duration": 0.0735457269474864,
        "outcome": "passed"
      },
      "call": {
        "duration": 1.0852967854589224,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.00029948819428682327,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]",
      "lineno": 114,
      "outcome": "passed",
      "keywords": [
        "test_chat_streaming_basic[meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-earth",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "earth"
      },
      "setup": {
        "duration": 0.07200248818844557,
        "outcome": "passed"
      },
      "call": {
        "duration": 0.41483108792454004,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0002880822867155075,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]",
      "lineno": 114,
      "outcome": "passed",
      "keywords": [
        "test_chat_streaming_basic[meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "saturn"
      },
      "setup": {
        "duration": 0.07424226123839617,
        "outcome": "passed"
      },
      "call": {
        "duration": 1.1533718826249242,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.00026405230164527893,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
      "lineno": 138,
      "outcome": "passed",
      "keywords": [
        "test_chat_non_streaming_image[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-case0",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "case0"
      },
      "setup": {
        "duration": 0.07035014033317566,
        "outcome": "passed"
      },
      "call": {
        "duration": 11.941276826895773,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0002712151035666466,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
      "lineno": 157,
      "outcome": "passed",
      "keywords": [
        "test_chat_streaming_image[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-case0",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "case0"
      },
      "setup": {
        "duration": 0.08027863781899214,
        "outcome": "passed"
      },
      "call": {
        "duration": 5.189308542758226,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.000255669467151165,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]",
      "lineno": 181,
      "outcome": "passed",
      "keywords": [
        "test_chat_non_streaming_structured_output[meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "calendar"
      },
      "setup": {
        "duration": 0.07215503882616758,
        "outcome": "passed"
      },
      "call": {
        "duration": 7.25669299531728,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0002499222755432129,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[meta-llama/Llama-4-Scout-17B-16E-Instruct-math]",
      "lineno": 181,
      "outcome": "passed",
      "keywords": [
        "test_chat_non_streaming_structured_output[meta-llama/Llama-4-Scout-17B-16E-Instruct-math]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-math",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "math"
      },
      "setup": {
        "duration": 0.0723958220332861,
        "outcome": "passed"
      },
      "call": {
        "duration": 23.26972564868629,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0002250121906399727,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]",
      "lineno": 204,
      "outcome": "passed",
      "keywords": [
        "test_chat_streaming_structured_output[meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "calendar"
      },
      "setup": {
        "duration": 0.0755303306505084,
        "outcome": "passed"
      },
      "call": {
        "duration": 6.047801445238292,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.00023919064551591873,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[meta-llama/Llama-4-Scout-17B-16E-Instruct-math]",
      "lineno": 204,
      "outcome": "passed",
      "keywords": [
        "test_chat_streaming_structured_output[meta-llama/Llama-4-Scout-17B-16E-Instruct-math]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-math",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "math"
      },
      "setup": {
        "duration": 0.07097675651311874,
        "outcome": "passed"
      },
      "call": {
        "duration": 26.09199330676347,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.00032348278909921646,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
      "lineno": 226,
      "outcome": "passed",
      "keywords": [
        "test_chat_non_streaming_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-case0",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "case0"
      },
      "setup": {
        "duration": 0.07283070310950279,
        "outcome": "passed"
      },
      "call": {
        "duration": 0.7768763303756714,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0002704216167330742,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
      "lineno": 250,
      "outcome": "passed",
      "keywords": [
        "test_chat_streaming_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-case0",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "case0"
      },
      "setup": {
        "duration": 0.07072548102587461,
        "outcome": "passed"
      },
      "call": {
        "duration": 0.7484909351915121,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0002851812168955803,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
      "lineno": 278,
      "outcome": "passed",
      "keywords": [
        "test_chat_non_streaming_tool_choice_required[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-case0",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "case0"
      },
      "setup": {
        "duration": 0.07187876384705305,
        "outcome": "passed"
      },
      "call": {
        "duration": 0.7497121002525091,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.00029664672911167145,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
      "lineno": 302,
      "outcome": "passed",
      "keywords": [
        "test_chat_streaming_tool_choice_required[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-case0",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "case0"
      },
      "setup": {
        "duration": 0.07151791825890541,
        "outcome": "passed"
      },
      "call": {
        "duration": 1.1092564295977354,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0002770284190773964,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
      "lineno": 329,
      "outcome": "passed",
      "keywords": [
        "test_chat_non_streaming_tool_choice_none[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-case0",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "case0"
      },
      "setup": {
        "duration": 0.07284159772098064,
        "outcome": "passed"
      },
      "call": {
        "duration": 28.572499179281294,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.00031286943703889847,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
      "lineno": 352,
      "outcome": "passed",
      "keywords": [
        "test_chat_streaming_tool_choice_none[meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-case0",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "case0"
      },
      "setup": {
        "duration": 0.07455504685640335,
        "outcome": "passed"
      },
      "call": {
        "duration": 27.01730054244399,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0002900902181863785,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]",
      "lineno": 380,
      "outcome": "passed",
      "keywords": [
        "test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "text_then_weather_tool"
      },
      "setup": {
        "duration": 0.10514138638973236,
        "outcome": "passed"
      },
      "call": {
        "duration": 2.5916615584865212,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0003233887255191803,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]",
      "lineno": 380,
      "outcome": "passed",
      "keywords": [
        "test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "weather_tool_then_text"
      },
      "setup": {
        "duration": 0.09724622592329979,
        "outcome": "passed"
      },
      "call": {
        "duration": 1.6816193973645568,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0002651568502187729,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]",
      "lineno": 380,
      "outcome": "passed",
      "keywords": [
        "test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "add_product_tool"
      },
      "setup": {
        "duration": 0.0717660365626216,
        "outcome": "passed"
      },
      "call": {
        "duration": 2.301668006926775,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0002871360629796982,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]",
      "lineno": 380,
      "outcome": "passed",
      "keywords": [
        "test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "get_then_create_event_tool"
      },
      "setup": {
        "duration": 0.07237224746495485,
        "outcome": "passed"
      },
      "call": {
        "duration": 4.44710533414036,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.000309748575091362,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]",
      "lineno": 380,
      "outcome": "passed",
      "keywords": [
        "test_chat_non_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "compare_monthly_expense_tool"
      },
      "setup": {
        "duration": 0.07419578451663256,
        "outcome": "passed"
      },
      "call": {
        "duration": 3.0712353149428964,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0003073718398809433,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]",
      "lineno": 471,
      "outcome": "passed",
      "keywords": [
        "test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "text_then_weather_tool"
      },
      "setup": {
        "duration": 0.07015236373990774,
        "outcome": "passed"
      },
      "call": {
        "duration": 2.4258732767775655,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0002886578440666199,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]",
      "lineno": 471,
      "outcome": "passed",
      "keywords": [
        "test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "weather_tool_then_text"
      },
      "setup": {
        "duration": 0.07009198423475027,
        "outcome": "passed"
      },
      "call": {
        "duration": 1.7146461214870214,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0003043804317712784,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]",
      "lineno": 471,
      "outcome": "passed",
      "keywords": [
        "test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "add_product_tool"
      },
      "setup": {
        "duration": 0.07378454692661762,
        "outcome": "passed"
      },
      "call": {
        "duration": 2.3185672890394926,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0002978481352329254,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]",
      "lineno": 471,
      "outcome": "passed",
      "keywords": [
        "test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "get_then_create_event_tool"
      },
      "setup": {
        "duration": 0.07212705258280039,
        "outcome": "passed"
      },
      "call": {
        "duration": 4.408322776667774,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0003781057894229889,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]",
      "lineno": 471,
      "outcome": "passed",
      "keywords": [
        "test_chat_streaming_multi_turn_tool_calling[meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "compare_monthly_expense_tool"
      },
      "setup": {
        "duration": 0.07353641279041767,
        "outcome": "passed"
      },
      "call": {
        "duration": 3.327573754824698,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.0003117518499493599,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=False]",
      "lineno": 554,
      "outcome": "passed",
      "keywords": [
        "test_chat_multi_turn_multiple_images[meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=False]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=False",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "stream=False"
      },
      "setup": {
        "duration": 0.07416135538369417,
        "outcome": "passed"
      },
      "call": {
        "duration": 17.42448517587036,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.00031717773526906967,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=True]",
      "lineno": 554,
      "outcome": "passed",
      "keywords": [
        "test_chat_multi_turn_multiple_images[meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=True]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=True",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "stream=True"
      },
      "setup": {
        "duration": 0.07180674187839031,
        "outcome": "passed"
      },
      "call": {
        "duration": 9.833569367416203,
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multiple_images[meta-llama/Llama-4-Scout-17B-16E-Instruct-True]",
      "lineno": 554,
      "outcome": "failed",
      "keywords": [
        "test_chat_multiple_images[meta-llama/Llama-4-Scout-17B-16E-Instruct-True]",
        "parametrize",
        "pytestmark",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct-True",
        "test_chat_completion.py",
        "openai_api",
        "verifications",
        "tests",
        "llama-stack",
        ""
      ],
      "metadata": {
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "case_id": "True"
      },
      "setup": {
        "duration": 0.01194374999977299,
        "outcome": "passed"
      },
      "call": {
        "duration": 1.3468280830002186,
        "outcome": "failed",
        "crash": {
          "path": "/Users/erichuang/.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py",
          "lineno": 989,
          "message": "openai.APIConnectionError: Connection error."
        },
        "traceback": [
          {
            "path": "tests/verifications/openai_api/test_chat_completion.py",
            "lineno": 586,
            "message": ""
          },
          {
            "path": "../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_utils/_utils.py",
            "lineno": 279,
            "message": "in wrapper"
          },
          {
            "path": "../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py",
            "lineno": 914,
            "message": "in create"
          },
          {
            "path": "../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py",
            "lineno": 1242,
            "message": "in post"
          },
          {
            "path": "../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py",
            "lineno": 919,
            "message": "in request"
          },
          {
            "path": "../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py",
            "lineno": 979,
            "message": "in _request"
          },
          {
            "path": "../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py",
            "lineno": 1057,
            "message": "in _retry_request"
          },
          {
            "path": "../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py",
            "lineno": 979,
            "message": "in _request"
          },
          {
            "path": "../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py",
            "lineno": 1057,
            "message": "in _retry_request"
          },
          {
            "path": "../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py",
            "lineno": 989,
            "message": "APIConnectionError"
          }
        ],
        "longrepr": "@contextlib.contextmanager\n    def map_httpcore_exceptions() -> typing.Iterator[None]:\n        global HTTPCORE_EXC_MAP\n        if len(HTTPCORE_EXC_MAP) == 0:\n            HTTPCORE_EXC_MAP = _load_httpcore_exceptions()\n        try:\n>           yield\n\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpx/_transports/default.py:101: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpx/_transports/default.py:250: in handle_request\n    resp = self._pool.handle_request(req)\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256: in handle_request\n    raise exc from None\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236: in handle_request\n    response = connection.handle_request(\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpcore/_sync/connection.py:101: in handle_request\n    raise exc\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpcore/_sync/connection.py:78: in handle_request\n    stream = self._connect(request)\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpcore/_sync/connection.py:124: in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpcore/_backends/sync.py:207: in connect_tcp\n    with map_exceptions(exc_map):\n/opt/homebrew/Caskroom/miniconda/base/envs/myenv/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmap = {<class 'TimeoutError'>: <class 'httpcore.ConnectTimeout'>, <class 'OSError'>: <class 'httpcore.ConnectError'>}\n\n    @contextlib.contextmanager\n    def map_exceptions(map: ExceptionMapping) -> typing.Iterator[None]:\n        try:\n            yield\n        except Exception as exc:  # noqa: PIE786\n            for from_exc, to_exc in map.items():\n                if isinstance(exc, from_exc):\n>                   raise to_exc(exc) from exc\nE                   httpcore.ConnectError: [Errno 61] Connection refused\n\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpcore/_exceptions.py:14: ConnectError\n\nThe above exception was the direct cause of the following exception:\n\nself = <openai.OpenAI object at 0x107bd0250>\n\n    def _request(\n        self,\n        *,\n        cast_to: Type[ResponseT],\n        options: FinalRequestOptions,\n        retries_taken: int,\n        stream: bool,\n        stream_cls: type[_StreamT] | None,\n    ) -> ResponseT | _StreamT:\n        # create a copy of the options we were given so that if the\n        # options are mutated later & we then retry, the retries are\n        # given the original options\n        input_options = model_copy(options)\n    \n        cast_to = self._maybe_override_cast_to(cast_to, options)\n        options = self._prepare_options(options)\n    \n        remaining_retries = options.get_max_retries(self.max_retries) - retries_taken\n        request = self._build_request(options, retries_taken=retries_taken)\n        self._prepare_request(request)\n    \n        kwargs: HttpxSendArgs = {}\n        if self.custom_auth is not None:\n            kwargs[\"auth\"] = self.custom_auth\n    \n        log.debug(\"Sending HTTP Request: %s %s\", request.method, request.url)\n    \n        try:\n>           response = self._client.send(\n                request,\n                stream=stream or self._should_stream_response_body(request=request),\n                **kwargs,\n            )\n\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py:955: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpx/_client.py:914: in send\n    response = self._send_handling_auth(\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpx/_client.py:942: in _send_handling_auth\n    response = self._send_handling_redirects(\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpx/_client.py:979: in _send_handling_redirects\n    response = self._send_single_request(request)\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpx/_client.py:1014: in _send_single_request\n    response = transport.handle_request(request)\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpx/_transports/default.py:249: in handle_request\n    with map_httpcore_exceptions():\n/opt/homebrew/Caskroom/miniconda/base/envs/myenv/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    @contextlib.contextmanager\n    def map_httpcore_exceptions() -> typing.Iterator[None]:\n        global HTTPCORE_EXC_MAP\n        if len(HTTPCORE_EXC_MAP) == 0:\n            HTTPCORE_EXC_MAP = _load_httpcore_exceptions()\n        try:\n            yield\n        except Exception as exc:\n            mapped_exc = None\n    \n            for from_exc, to_exc in HTTPCORE_EXC_MAP.items():\n                if not isinstance(exc, from_exc):\n                    continue\n                # We want to map to the most specific exception we can find.\n                # Eg if `exc` is an `httpcore.ReadTimeout`, we want to map to\n                # `httpx.ReadTimeout`, not just `httpx.TimeoutException`.\n                if mapped_exc is None or issubclass(to_exc, mapped_exc):\n                    mapped_exc = to_exc\n    \n            if mapped_exc is None:  # pragma: no cover\n                raise\n    \n            message = str(exc)\n>           raise mapped_exc(message) from exc\nE           httpx.ConnectError: [Errno 61] Connection refused\n\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/httpx/_transports/default.py:118: ConnectError\n\nThe above exception was the direct cause of the following exception:\n\nrequest = <FixtureRequest for <Function test_chat_multiple_images[meta-llama/Llama-4-Scout-17B-16E-Instruct-True]>>\nopenai_client = <openai.OpenAI object at 0x107bd0250>\nmodel = 'meta-llama/Llama-4-Scout-17B-16E-Instruct', provider = 'meta_reference'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\nmulti_image_data = ['data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGC...6pH9jaTzNv7vfRRXzubfxj9f8Pv8AkTz/AMX/ALbEz5Ly38lfMk/5Z/u64PxhqEZh+z/6rzvn2UUV5EvgPuzy/wAc6p5dt5ccibJpNkkdFFFec27mZ//Z']\nstream = True\n\n    @pytest.mark.parametrize(\"stream\", [False, True])\n    def test_chat_multiple_images(request, openai_client, model, provider, verification_config, multi_image_data, stream):\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        messages_turn1 = [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\n                            \"url\": multi_image_data[0],\n                        },\n                    },\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\n                            \"url\": multi_image_data[1],\n                        },\n                    },\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"What furniture is in the first image that is not in the second image?\",\n                    },\n                ],\n            },\n        ]\n    \n        # First API call\n>       response1 = openai_client.chat.completions.create(\n            model=model,\n            messages=messages_turn1,\n            stream=stream,\n        )\n\ntests/verifications/openai_api/test_chat_completion.py:586: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_utils/_utils.py:279: in wrapper\n    return func(*args, **kwargs)\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:914: in create\n    return self._post(\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py:1242: in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py:919: in request\n    return self._request(\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py:979: in _request\n    return self._retry_request(\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py:1057: in _retry_request\n    return self._request(\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py:979: in _request\n    return self._retry_request(\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py:1057: in _retry_request\n    return self._request(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <openai.OpenAI object at 0x107bd0250>\n\n    def _request(\n        self,\n        *,\n        cast_to: Type[ResponseT],\n        options: FinalRequestOptions,\n        retries_taken: int,\n        stream: bool,\n        stream_cls: type[_StreamT] | None,\n    ) -> ResponseT | _StreamT:\n        # create a copy of the options we were given so that if the\n        # options are mutated later & we then retry, the retries are\n        # given the original options\n        input_options = model_copy(options)\n    \n        cast_to = self._maybe_override_cast_to(cast_to, options)\n        options = self._prepare_options(options)\n    \n        remaining_retries = options.get_max_retries(self.max_retries) - retries_taken\n        request = self._build_request(options, retries_taken=retries_taken)\n        self._prepare_request(request)\n    \n        kwargs: HttpxSendArgs = {}\n        if self.custom_auth is not None:\n            kwargs[\"auth\"] = self.custom_auth\n    \n        log.debug(\"Sending HTTP Request: %s %s\", request.method, request.url)\n    \n        try:\n            response = self._client.send(\n                request,\n                stream=stream or self._should_stream_response_body(request=request),\n                **kwargs,\n            )\n        except httpx.TimeoutException as err:\n            log.debug(\"Encountered httpx.TimeoutException\", exc_info=True)\n    \n            if remaining_retries > 0:\n                return self._retry_request(\n                    input_options,\n                    cast_to,\n                    retries_taken=retries_taken,\n                    stream=stream,\n                    stream_cls=stream_cls,\n                    response_headers=None,\n                )\n    \n            log.debug(\"Raising timeout error\")\n            raise APITimeoutError(request=request) from err\n        except Exception as err:\n            log.debug(\"Encountered Exception\", exc_info=True)\n    \n            if remaining_retries > 0:\n                return self._retry_request(\n                    input_options,\n                    cast_to,\n                    retries_taken=retries_taken,\n                    stream=stream,\n                    stream_cls=stream_cls,\n                    response_headers=None,\n                )\n    \n            log.debug(\"Raising connection error\")\n>           raise APIConnectionError(request=request) from err\nE           openai.APIConnectionError: Connection error.\n\n../../.cache/uv/archive-v0/OInMrHyP7p3zvGOl93HK1/lib/python3.10/site-packages/openai/_base_client.py:989: APIConnectionError"
      },
      "teardown": {
        "duration": 0.0012101922184228897,
        "outcome": "passed"
      }
    }
  ],
  "run_timestamp": 1744915311
}
